# paper
## [BEVGM: A Visual Place Recognition Method With Birdâ€™s Eye View Graph Matching](https://ieeexplore.ieee.org/document/10502165/)
### (10/10/2024)
### METHODS
1. BEV Graph Construction: To better preserve the semantic and structural information of the scene, the paper partition the pixel-level semantic labels into foreground elements, and background elements.  
1) Node Representation: Extract the foreground categories and apply morphological operations to remove small connected regions caused by noise.
2) Edge Representation: Establish undirected edges between each pair of nodes.  
2. Similarity Measurement
1) Similarity Definition: Define the similarity between nodes and edges by using different functions.
2) Graph Matching: Employ an iterative solver to solve the graph matching problem.  
![1.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/BEVGM_1.png)
3) Adaptive Reranking: Design an adaptive fusion strategy to fuse the two-stage scores.  
![2.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/BEVGM_2.png)

---------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------------------

# Code
Have a problem when GLVI-fusion ran Rosbag of short sequence.
### (11/10/2024)
![5.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/campus_10_11.png)

GNSS factor invalid running GLVI-fusion.
### (12/10/2024)
![6.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/10_12.png)
![7.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/GLVI_diagram.png)

---------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------------------

# Other
### (09/10/2024)
1. The difference between scan-scan, scan-map, and scan-multiscan in lidar point clouds and the point-to-plane residual.
1) scan-scan: Match the current frame to the last frame, which optimises the conversion matrix.  
scan-map: Match the current frame to the world map, which upgrades the actual world map.
scan-multiscan: Match multiple keyframes in the neighborhood.
2) point-to-plane residual:  

![3.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/point-to-plane_1.jpg)  

![4.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/point-to-plane_2.png)  

---------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------------------

# Summary
1. Read the paper about matching features of SLAM using BEV Graph.
2. Solve questions left over from last week.
3. Have some questions running GLVI. 
# Plan 
1. Solve code quesitons of GLVI.
2. Read papers about multisensor fusion to mine methods of data fusion.
# Problem
1. Code questions of GLVI