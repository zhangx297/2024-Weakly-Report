# Book
## [DIVE INTO DEEP LEARNING](https://github.com/zhangx297/DIVE-INTO-DEEP-LEARNING):
### Code of Chapter nine to ten: Modern RNN and Attention (13/01/2024 - 16/01/2024)
1. **[GRU.py](https://github.com/zhangx297/DIVE-INTO-DEEP-LEARNING/blob/main/lecture_8/GRU.py)**  
2. **[seq2seq.py](https://github.com/zhangx297/DIVE-INTO-DEEP-LEARNING/blob/main/lecture_8/seq2seq.py)**  
3. **[Attention](https://github.com/zhangx297/DIVE-INTO-DEEP-LEARNING/blob/main/lecture_9/attention.py)**  

![Attention.png](https://github.com/zhangx297/DIVE-INTO-DEEP-LEARNING/blob/main/lecture_9/attention.png)
### Read of Chapter nine to ten:
1. Because of Attention Mechanism based on seq-to-seq architecture, learnt seq-to-seq model and GRU.
2. Learnt Attention Mechanism so that understanding Transformer. 
3. Recalled knowledge of deep learning about Optimisation Algorithm, Computational Performance and Computer Vision.
# Paper
## [A Novel Feature Points Tracking Algorithm in Terms of IMU-Aided Information Fusion](https://ieeexplore.ieee.org/document/9197627)
### (16/01/2024 - 17/01/2024)
### Introduction && Related word
1. Proposed source of IMU
2. Early works about feature matching, descriptors and IMU
### Methods
1. VINS estimates poses, 3-D positions and IMU Preintegration estimates poses.
2. Prediction of Feature Points Position.
3. Local Detector With a Search Window: 
    1) Proposed different sizes of Search Window for feature matching, which can avoid brute force searching.

    ![1.png](https://github.com/zhangx297/2024-Weakly-Report/blob/main/Pictures%20of%20papers/A%20Novel%20Feature%20Points%20Tracking%20Algorithm%20in%20Terms%20of%20IMU-Aided%20Information%20Fusion_2.png)
    2) Proposed a feature update method to prevent biological population by removing some feature points of converge.

    ![2.png](https://github.com/zhangx297/2024-Weakly-Report/blob/main/Pictures%20of%20papers/A%20Novel%20Feature%20Points%20Tracking%20Algorithm%20in%20Terms%20of%20IMU-Aided%20Information%20Fusion_3.png)
    3) Employed to guide the generation of new features.
    
![3.png](https://github.com/zhangx297/2024-Weakly-Report/blob/main/Pictures%20of%20papers/A%20Novel%20Feature%20Points%20Tracking%20Algorithm%20in%20Terms%20of%20IMU-Aided%20Information%20Fusion_1.png)
### contribution
1. Proposed a new feature points tracking algorithm in terms of IMU-aid information fusion.
2. Proposed novel the local matcher and feature update module
### Advantages and Disadvantages
1. A superior performance in accuracy and efficiency 
### Problem
Because I can not understand knowledge about preintegration, the formula is not derived. (Some of the content about Methods will be refined next week)
## [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
### (17/01/2024 - 18/01/2024)
### Introduction && Related word
1. Early approaches in sequence modeling about CNN and RNN
2. CNN and RNN some drawbacks about sequence lengths and computational efficiency
### Methods
1. Encoder and Decoder Stacks  
![1.png](https://github.com/zhangx297/2024-Weakly-Report/blob/main/Pictures%20of%20papers/Attention%20Is%20All%20You%20Need_1.png)
2. Model of Transformer:
    1) Attentions about Scaled Dot-Product Attention and Multi-Head Attention  
    ![2.png](https://github.com/zhangx297/2024-Weakly-Report/blob/main/Pictures%20of%20papers/Attention%20Is%20All%20You%20Need_2.png)
    2) Position-wise Feed-Forward Networks
    3) Embeddings and Softmax
    4) Positional Encoding
### contribution
Proposed the Transformer of the first model based entirely on attention, replacing the RNN and CNN
### Advantages and Disadvantages
The Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers for translation tasks.
### Problem
Only at the theoretical stage, I have not run actually code of transformer.
## [On-Manifold Preintegration for Real-Time Visual--Inertial Odometry](https://ieeexplore.ieee.org/document/7557075)
### (18/01/2024 - 19/01/2024)
### Introduction && Related word
1. Introduce cameras, inertial sensors and the existing literatureon VIO imposing a tradeoff between the accuracy and computational efficiency.
2. Related work on VIO can be sectioned along three main dimensions:
    1) The number of camera poses involved in the estimation:  
        * Filtering
        * Fixed-Lag Smoothing
        * Full Smoothing
    2) The representation of the uncertainty for the measurements and the Gaussian priors
    3) Distinguishes existing approaches by looking at the number of times in which the measurement model is linearized. 
### Methods
1. PRELIMINARIES:
    1) Notions of Riemannian Geometry
    2) Uncertainty Description in SO(3)
    3) Gauss–Newton Method on Manifold
2. MAP VISUAL–INERTIAL STATE ESTIMATION
![MAP VISUAL–INERTIAL STATE ESTIMATION](https://github.com/zhangx297/2024-Weakly-Report/blob/main/Pictures%20of%20papers/On-Manifold%20Preintegration%20for%20Real-Time%20Visual--Inertial%20Odometry_1.png)
3. IMU MODEL AND MOTION INTEGRATION
4. IMU PREINTEGRATION ON MANIFOLD
    1) Preintegrated IMU Measurements
    2) Noise Propagation
    3) Incorporating Bias Updates
    4) Preintegrated IMU Factors
    5) Bias Model
1[IMU PREINTEGRATION ON MANIFOLD](https://github.com/zhangx297/2024-Weakly-Report/blob/main/Pict    ures%20of%20papers/On-Manifold%20Preintegration%20for%20Real-Time%20Visual--Inertial%20Odometry_2.png)
5.  STRUCTURELESS VISION FACTORS
### contribution 
1. Proposed a novel preintegration theory, which Improved integration in a global frame.
2. Adopted a structureless model for visual measurements which avoids optimizing over 3-D landmarks.
### Advantages and Disadvantages
### Problem
A part of the content about experimental analysis and the second time derivation formula does not read. (Some of the content about Methods, contribution and Advantages and Disadvantages will be refined next week)
# Summary
1. Completed the code for the DIVE INTO DEEP LEARNING as well as reviewing some of the knowledge associated with deep learning.
2. Readed the two papers about IMU-Aided and Preintegration.
3. Readed Attention Mechanisms and knowledge about Transformer.
# Plan
1. I will complete two unfinished papers for derivation formula and experimental analysis.
2. Read "Inertial preintegration for VI‐SLAM by the screw motion theory".
3. Read "BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird’s-Eye View Representation" again.
# Problem
1. Problems in the above Papers.
2. The book of DIVE INTO DEEP LEARNING have not compiling some codes, because the one of python library of this book have some questions. That will do not affact study in the future. 