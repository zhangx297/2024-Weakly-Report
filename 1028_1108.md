# paper 
## [Continuous-Time Fixed-Lag Smoothing for LiDAR-Inertial-Camera SLAM](https://arxiv.org/abs/2302.07456)
### (04/11/2024 - 05/11/2024)
### METHOD
1. PRELIMINARY ON CONTINUOUS-TIME TRAJECTORY
    1) B-spline Trajectory Representation:
    ![1.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/B-spline_1.jpg)
    ![1_2.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/B-spline_2.jpg)
    2) Time Derivatives of B-spline
        * Factor-Graph Optimization
        * LiDAR Factor
        ![2.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/Deruvative_B-spline_1.jpg)
        * IMU Factor and Bias Factor
        ![3.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/Deruvative_B-spline_2.jpg)
        ![4.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/Deruvative_B-spline_3.jpg)
        * Visual Factor
        * Marginalization
2. MULTI-SENSOR FUSION
    1) LiDAR-Inertial System
        * LiDAR Measurement Processing: Compute the curvature → planar features → the continuous-time trajectory compensate the points of motion distortion → point-to-plane data association → optimize estimation  
        * LI Temporal Sliding Window: Propose a temporal sliding window within a constant time duration. The continuous-time trajectory of LI system is optimized and updated every delta t seconds
    2) Visual System
        * Visual Front End: Extract corner features → triangulate query current best-estimated continuous-time trajectory
        * Visual Keyframe Sliding Window: Triangulation needs to maintain a visual keyframe sliding window with a constant number of keyframes, in contrast to the constant time duration for LI temporal sliding window. In practice, they determine the trajectory optimization range based on the temporal sliding window of the LI system and define the control points to be optimized as active control points.  
    3) Extra Implementation Details
        * Initialization: Stationary: The new IMU biases are initialized to the value of the previous temporal sliding window bias, and the new control points are first assigned values of the neighboring control points and further initialized via factor graph optimization. Motion: Use the raw IMU measurements  
        * Online Calibration of Timeoffset: The paper choose the LiDAR sensor as the time baseline. The main reason of choosing LiDAR as the base sensor is that local LiDAR map needs to be maintained
        * Loop Closure: Utilize Euclidean distance-based loop closure detection method. After a loop closure optimization, the paper remove the prior information of states since the current best-estimated states may be away from the linearized points, resulting in inappropriate prior constraints.  

### Code
1. The dmeo of Continuous-Time Fixed-Lag: 
    1) eee_01:
    ![5.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/eee_01.png)
    2) eee_02:
    ![6.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/eee_02.png)
### PPT
[paper_pptx](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/%E8%AE%BA%E6%96%87%E6%B1%87%E6%8A%A5.pdf)

## [An_Optimization-Based_IndoorOutdoor_Seamless_Positioning_Method_Integrating_GNSS_RTK_PS_and_VIO](https://www.researchgate.net/publication/377251291_An_Optimization-Based_Indoor-Outdoor_Seamless_Positioning_Method_Integrating_GNSS_RTK_PS_and_VIO)
### (07/11/2024)
### METHODS
1. System Overviews: The overall architecture of our proposed algorithm is depicted. The system is partitioned into four modules: sensors, pre-processing, initialization, and optimization.
2. Factor Graph Optimization
    1) Frames and Notations
    2) Maximum a Posteriori Estimation
    3) IMU Preintegration Factor
    4) Visual Reprojection Factor
    5) GNSS RTK Factor
    6) PS Factor
    ![7.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/An_Optimization-Based_IndoorOutdoor_Seamless_Positioning_Method_Integrating_GNSS_RTK_PS_and_VIO_1.png)

## [HVL-SLAM_Hybrid_Vision_and_LiDAR_Fusion_for_SLAM](https://ieeexplore.ieee.org/document/10606294/)
### (08/11/2024)
### METHODS
1. Overview: System contains three running threads: a frame-to-frame tracking thread, a visual-LiDAR jointly optimization thread, and a loop closure detection thread. (lidar:ground extraction; camera:nonground; Delaunay triangulation; interpolate method)
![1.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/HVL-SLAM_Hybrid_Vision_and_LiDAR_Fusion_for_SLAM_1.png) 
2. LSDT Depth Fitting: Describe the depth fitting method to extract the point depth from the LiDAR data based on object segmentation and Delaunay triangulation.
![2.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/HVL-SLAM_Hybrid_Vision_and_LiDAR_Fusion_for_SLAM_2.png)
![3.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/HVL-SLAM_Hybrid_Vision_and_LiDAR_Fusion_for_SLAM_3.png)
3. Hybrid Visual LiDAR Frame-to-Frame Tracking
    1) Photometric Residual: Minimize the photometric errors only for those pixels with depth which are composed of two types: the selected salient LiDAR points, and the ORB feature point. (LiDAR points outside the camera's field of view)
    2) Geometric Residual: Denote pi and pj one of the matched corresponding features within the last frame and the current frame to compute reprojection error.
4. Visual-LiDAR Jointly Local Mapping:  Fuse the visual reprojection factors and LiDAR scan-to-map factors to refine the pose of the current keyframe and local visual map points.
    1) Visual Constraint
    2) Lidar Edge Constraint
    3) Lidar Planar Constraints
    4) Lidar Ground Constraints
5. Loop Closure Detection and Pose-Graph Optimization

---------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------------------
# code
### (28/10/2024 and 06/11/2024 - 07/11/2024)
1. The demo of Glomap with Tooth Dadaset: When I run clomap and glomap using the tooth dataset, I find that there are not almost generated feature points in the GUI, but the public dataset has many feature points.  
    1) clomap
    ![8.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/clomap_tooth.png)
    ![10.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/clomap_tooth_2.png)
    2) glomap
    ![9.png](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/glomap_tooth.png)

2. GLVI: Construct a system of GLVI-SAM → Plan construction code by reading related code → Modify codes → Solve Problems of timestamps of datasets → Experiments of datasets.  

---------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------------------

# Summary
1. Read papers about SLAM.
2. Construct codes about GLVI. 
3. Finish codes about Glomap.
# Plan
1. Read papers about SLAM
2. Modify codes → Solve Problems of timestamps of datasets → Experiments of datasets
# Problem
1. The paper questions of continuous-time Fixed-Lag smoothing.