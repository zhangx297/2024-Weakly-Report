# paper
## [A Novel Feature Points Tracking Algorithm in Terms of IMU-Aided Information Fusion](https://ieeexplore.ieee.org/document/9197627)
### (06/05/2024 - 07/05/2024)
### Code
```c
    bool Tracking::TrackWithMotionModel(){
        if (mpAtlas->isImuInitialized() && (mCurrentFrame.mnId>mnLastRelocFrameId+mnFramesToResetIMU))
        {
            // Predict state with IMU if it is initialized and it doesnt need reset
            PredictStateIMU();

            //IMU预测位姿
            //------------------------------------------------
            Eigen::Matrix3f Rbi_bj = IMU::NormalizeRotation(mpImuPreintegratedFromLastKF->GetDeltaRotation(mpLastKeyFrame->GetImuBias())); 
            // 计算R的相对变化 
            Eigen::Matrix3f Rci_cj = (Rbc-1)*Rbi_bj*Rbc;

            Eigen::Vector3f delta_t = mpImuPreintegratedFromLastKF->GetDeltaPosition(mpLastKeyFrame->GetImuBias());
            Eigen::Vector3f delta_v = mpImuPreintegratedFromLastKF->GetDeltaVelocity(mpLastKeyFrame->GetImuBias());

            // 解线性方程计算相对位置的变化（差一个惯导上速度的参数）
            Eigen::Vector3f DeltaVij = ;
            Eigen::Vector3f DeltaPij = ;
            // Eigen::Vector3f mVw = Vwb;
            // delta_v + mVelocity - Rcb*G*t12
            // delta_t - Rbc*Rci_cj*pcb + mVelocity*t12 - 0.5*Rbc*G*t12*t12
            // vpj+1
            // vj = vj+1
            // G = (Rci_cj)-1*G
            Sophus::SE3f Twb(delta_R, delta_t);
            Sophus::SE3f Tbw = Twb.inverse();

            //特征点匹配，对极约束利用SVD求解
            Prediction_Feature_points();
            //------------------------------------------------
            return true;

        }
        else
        {
            // 估计当前帧的位姿（恒速模式下）
            mCurrentFrame.SetPose(mVelocity * mLastFrame.GetPose());
        }
    }
```

# Code
## [Resilient_and_Distributed_Multi-Robot_Visual_SLAM_Datasets_Experiments_and_Lessons_Learned](https://www.researchgate.net/publication/376505892_Resilient_and_Distributed_Multi-Robot_Visual_SLAM_Datasets_Experiments_and_Lessons_Learned)
### (07/05/2024 - 10/05/2024)
As shown in the figure, when I have run codes of Multi-Robot, I find there are feature points of robots in the rviz, but the picture of rviz has no trajectory of robots.  
![1.jpg](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/Resilient_and_Distributed_Multi-Robot_Visual_SLAM_Datasets_Experiments_and_Lessons_Learned_1.jpg)
And then, the terminal has this warning. However, if I run six robots in the terminal, my cpu is overflowed. So I divided to run these codes in the DELL T3660.
![2.jpg](https://github.com/zhangx297/2024-Weekly-Report/blob/main/Pictures%20of%20papers/Resilient_and_Distributed_Multi-Robot_Visual_SLAM_Datasets_Experiments_and_Lessons_Learned_2.jpg)

# Technical Indicators of Project
### (11/05/2024 - 12/05/2024)
[pdf](https://github.com/zhangx297/2024-Weekly-Report/blob/main/paper/1_%E6%97%A0%E4%BA%BA%E8%BD%A6%E6%8A%80%E6%9C%AF%E6%8C%87%E6%A0%87.pdf)

# paper 
## [Optimization-Based Visual-Inertial SLAM Tightly Coupled with Raw GNSS Measurements](https://arxiv.org/abs/2010.11675)
### METHODS
1. GNSS-SLAM Initialization: At GNSS-SLAM initialization stage we align the above two trajectories, in order to compute the value of R and p, as well as the initial value of R and p.
2. Tightly Coupled Optimization: After GNSS-SLAM initialization, raw GNSS measurements, i.e. pseudoranges and Doppler shift, are integrated
into the optimization.
3. Sliding Window and Marginalization
4. Removing Noisy GNSS Measurements: Before the GNSS measurements enter into the sliding window for optimization, a filtering is carried out by one of the following two possible methods.

## [Resilient_and_Distributed_Multi-Robot_Visual_SLAM_Datasets_Experiments_and_Lessons_Learned(twice)](https://www.researchgate.net/publication/376505892_Resilient_and_Distributed_Multi-Robot_Visual_SLAM_Datasets_Experiments_and_Lessons_Learned)
### METHODS
1. Distributed Front-end
2. Distributed Robust Pose Graph Optimization
3. Inter-Robot Communication


# Summary
1. Read papers about GNSS.
2. Run GVINS and Resilient and Distributed Multi-Robot Visual.
# Plan 
1. Read books about SLAM.
# Problem
1. Problems in the above codes of Distributed Multi-Robot Visual.
